{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'))\n",
    "dataset_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\n",
    "dataset_test = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shahd/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/hashing.py:102: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "dataset = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "X1, y = dataset.data, dataset.target\n",
    "vectorizer = HashingVectorizer(stop_words='english', non_negative=True)\n",
    "X = vectorizer.transform(X1)\n",
    "features = features = dataset.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import sklearn.svm\n",
    "from sklearn.feature_extraction.text import HashingVectorizer ,TfidfVectorizer\n",
    "from sklearn.datasets import fetch_20newsgroups \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "def reduce_features(solution, features):\n",
    "    selected_elements_indices = numpy.where(solution == 1)[0]\n",
    "    reduced_features = features[:, selected_elements_indices]\n",
    "    return reduced_features\n",
    "\n",
    "\n",
    "def classification_accuracy(labels, predictions):\n",
    "    correct = numpy.where(labels == predictions)[0]\n",
    "    accuracy = correct.shape[0]/labels.shape[0]\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def cal_pop_fitness(pop, features, labels, train_indices, test_indices, indices):\n",
    "    accuracies = numpy.zeros(pop.shape[0])\n",
    "    idx = 0\n",
    "\n",
    "    for curr_solution in pop:\n",
    "        reduced_features = reduce_features(curr_solution, features)\n",
    "        train_data = reduced_features[train_indices, :]\n",
    "#         print (\"train_data: \", train_data.shape)\n",
    "        test_data = reduced_features[test_indices, :]\n",
    "#         print (\"test_data: \", test_data.shape)\n",
    "\n",
    "        train_labels = labels[train_indices]\n",
    "        \n",
    "        test_labels = labels[test_indices]\n",
    "        data_labels= labels[indices]\n",
    "        data = reduced_features[indices, :]\n",
    "        SV_classifier = MultinomialNB(alpha=0.3, class_prior=None, fit_prior=True)\n",
    "#         SV_classifier.fit(train_data, train_labels)\n",
    "#         sklearn.svm.SVC(gamma='scale')\n",
    "#         SV_classifier.fit(X=train_data, y=train_labels)\n",
    "\n",
    "#         predictions = SV_classifier.predict(test_data)\n",
    "#         accuracies[idx] = classification_accuracy(test_labels, predictions)\n",
    "#         print(features)\n",
    "        accuracies[idx] = cross_val_score(SV_classifier, data, data_labels, cv=5, scoring='accuracy').mean()\n",
    "        idx = idx + 1\n",
    "    return accuracies\n",
    "\n",
    "def select_mating_pool(pop, fitness, num_parents):\n",
    "    # Selecting the best individuals in the current generation as parents for producing the offspring of the next generation.\n",
    "    parents = numpy.empty((num_parents, pop.shape[1]))\n",
    "    for parent_num in range(num_parents):\n",
    "        max_fitness_idx = numpy.where(fitness == numpy.max(fitness))\n",
    "        max_fitness_idx = max_fitness_idx[0][0]\n",
    "        parents[parent_num, :] = pop[max_fitness_idx, :]\n",
    "        fitness[max_fitness_idx] = -99999999999\n",
    "    return parents\n",
    "\n",
    "\n",
    "def crossover(parents, offspring_size):\n",
    "    offspring = numpy.empty(offspring_size)\n",
    "    # The point at which crossover takes place between two parents. Usually, it is at the center.\n",
    "    crossover_point = numpy.uint8(offspring_size[1]/2)\n",
    "\n",
    "    for k in range(offspring_size[0]):\n",
    "        # Index of the first parent to mate.\n",
    "        parent1_idx = k%parents.shape[0]\n",
    "        # Index of the second parent to mate.\n",
    "        parent2_idx = (k+1)%parents.shape[0]\n",
    "        # The new offspring will have its first half of its genes taken from the first parent.\n",
    "        offspring[k, 0:crossover_point] = parents[parent1_idx, 0:crossover_point]\n",
    "        # The new offspring will have its second half of its genes taken from the second parent.\n",
    "        offspring[k, crossover_point:] = parents[parent2_idx, crossover_point:]\n",
    "    return offspring\n",
    "\n",
    "\n",
    "def mutation(offspring_crossover, num_mutations=2):\n",
    "    mutation_idx = numpy.random.randint(low=0, high=offspring_crossover.shape[1], size=num_mutations)\n",
    "    # Mutation changes a single gene in each offspring randomly.\n",
    "    for idx in range(offspring_crossover.shape[0]):\n",
    "        # The random value to be added to the gene.\n",
    "        offspring_crossover[idx, mutation_idx] = 1 - offspring_crossover[idx, mutation_idx]\n",
    "    return offspring_crossover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB 10-Cross Validation : 0.9232425531812523\n",
      "Number of training samples:  935\n",
      "Number of test samples:  935\n",
      "(900, 82269)\n",
      "Generation :  0\n",
      "Best result :  0.8935796166837233\n",
      "Generation :  1\n",
      "Best result :  0.8935796166837233\n",
      "Generation :  2\n",
      "Best result :  0.8935796166837233\n",
      "Generation :  3\n",
      "Best result :  0.8935796166837233\n",
      "Generation :  4\n",
      "Best result :  0.8935853669083414\n",
      "Generation :  5\n",
      "Best result :  0.8935853669083414\n",
      "Generation :  6\n",
      "Best result :  0.8935853669083414\n",
      "Generation :  7\n",
      "Best result :  0.8935853669083414\n",
      "Generation :  8\n",
      "Best result :  0.8935853669083414\n",
      "Generation :  9\n",
      "Best result :  0.8935853669083414\n",
      "Generation :  10\n",
      "Best result :  0.8935853669083414\n",
      "Generation :  11\n",
      "Best result :  0.8935853669083414\n",
      "Generation :  12\n",
      "Best result :  0.8941187002416747\n",
      "Generation :  13\n",
      "Best result :  0.8941187002416747\n",
      "Generation :  14\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import pickle\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot\n",
    "from sklearn.naive_bayes import MultinomialNB \n",
    "\n",
    "cats =['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware']\n",
    "dataset = fetch_20newsgroups(subset='all', categories=cats)\n",
    "\n",
    "X1, y = dataset.data, dataset.target\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.3, stop_words='english',smooth_idf =True)\n",
    "# vectorizer = HashingVectorizer(stop_words='english', non_negative=True)\n",
    "X = vectorizer.fit_transform(X1)\n",
    "# features = dataset.target_names\n",
    "data_outputs = dataset.target\n",
    "data_inputs = X\n",
    "est = MultinomialNB(alpha=0.3, class_prior=None, fit_prior=True)\n",
    "# tttt =cross_val_score(est, X, y, cv=5, scoring='accuracy').mean()\n",
    "print (\"MultinomialNB 10-Cross Validation :\",cross_val_score(est, data_inputs, data_outputs, cv=5, scoring='accuracy').mean())\n",
    "\n",
    "\n",
    "# f = open(\"dataset_features.pkl\", \"rb\")\n",
    "# data_inputs = pickle.load(f)\n",
    "# f.close()\n",
    "\n",
    "# f = open(\"outputs.pkl\", \"rb\")\n",
    "# data_outputs = pickle.load(f)\n",
    "# f.close()\n",
    "\n",
    "\n",
    "num_samples = data_inputs.shape[0]\n",
    "num_feature_elements = data_inputs.shape[1]\n",
    "\n",
    "train_indices = numpy.arange(1, num_samples, 4)\n",
    "test_indices = numpy.arange(0, num_samples, 4)\n",
    "indices = numpy.arange(0, num_samples, 2)\n",
    "print(\"Number of training samples: \", train_indices.shape[0])\n",
    "print(\"Number of test samples: \", test_indices.shape[0])\n",
    "\n",
    "\"\"\"\n",
    "Genetic algorithm parameters:\n",
    "    Population size\n",
    "    Mating pool size\n",
    "    Number of mutations\n",
    "\"\"\"\n",
    "sol_per_pop = 900 # Population size.\n",
    "num_parents_mating = 300 # Number of parents inside the mating pool.\n",
    "num_mutations = 30 # Number of elements to mutate.\n",
    "\n",
    "# Defining the population shape.\n",
    "pop_shape = (sol_per_pop, num_feature_elements)\n",
    "\n",
    "# Creating the initial population.\n",
    "new_population = numpy.random.randint(low=0, high=2, size=pop_shape)\n",
    "print(new_population.shape)\n",
    "\n",
    "best_outputs = []\n",
    "num_generations = 50\n",
    "for generation in range(num_generations):\n",
    "    print(\"Generation : \", generation)\n",
    "    # Measuring the fitness of each chromosome in the population.\n",
    "    fitness = cal_pop_fitness(new_population, data_inputs, data_outputs, train_indices, test_indices, indices)\n",
    "\n",
    "    best_outputs.append(numpy.max(fitness))\n",
    "    # The best result in the current iteration.\n",
    "    print(\"Best result : \", best_outputs[-1])\n",
    "\n",
    "    # Selecting the best parents in the population for mating.\n",
    "    parents = select_mating_pool(new_population, fitness, num_parents_mating)\n",
    "\n",
    "    # Generating next generation using crossover.\n",
    "    offspring_crossover = crossover(parents, offspring_size=(pop_shape[0]-parents.shape[0], num_feature_elements))\n",
    "\n",
    "    # Adding some variations to the offspring using mutation.\n",
    "    offspring_mutation = mutation(offspring_crossover, num_mutations=num_mutations)\n",
    "\n",
    "    # Creating the new population based on the parents and offspring.\n",
    "    new_population[0:parents.shape[0], :] = parents\n",
    "    new_population[parents.shape[0]:, :] = offspring_mutation\n",
    "\n",
    "# Getting the best solution after iterating finishing all generations.\n",
    "# At first, the fitness is calculated for each solution in the final generation.\n",
    "fitness = cal_pop_fitness(new_population, data_inputs, data_outputs, train_indices, test_indices, indices)\n",
    "# Then return the index of that solution corresponding to the best fitness.\n",
    "best_match_idx = numpy.where(fitness == numpy.max(fitness))[0]\n",
    "best_match_idx = best_match_idx[0]\n",
    "\n",
    "best_solution = new_population[best_match_idx, :]\n",
    "best_solution_indices = numpy.where(best_solution == 1)[0]\n",
    "best_solution_num_elements = best_solution_indices.shape[0]\n",
    "best_solution_fitness = fitness[best_match_idx]\n",
    "est = MultinomialNB(alpha=0.3, class_prior=None, fit_prior=True)\n",
    "tttt =cross_val_score(est, X[:,best_solution], y, cv=5, scoring='accuracy').mean()\n",
    "print (\"MultinomialNB 10-Cross Validation accuracy:\",tttt)\n",
    "\n",
    "print(\"best_match_idx : \", best_match_idx)\n",
    "print(\"best_solution : \", best_solution)\n",
    "print(\"Selected indices : \", best_solution_indices)\n",
    "print(\"Number of selected elements : \", best_solution_num_elements)\n",
    "print(\"Best solution fitness : \", best_solution_fitness)\n",
    "\n",
    "matplotlib.pyplot.plot(best_outputs)\n",
    "matplotlib.pyplot.xlabel(\"Iteration\")\n",
    "matplotlib.pyplot.ylabel(\"Fitness\")\n",
    "matplotlib.pyplot.show()\n",
    "# 0.9232425531812523\n",
    "# 0.9112133005119546\n",
    "# 0.911742689829231\n",
    "# 0.878171970381991\n",
    "# 0.8925071997924384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_solution)\n",
    "\n",
    "sol_per_pop = 400 # Population size.\n",
    "num_parents_mating = 200 # Number of parents inside the mating pool.\n",
    "num_mutations = 30 # Number of elements to mutate\n",
    "0.8952199143808468"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.8727272727272727\n",
    "0.8716577540106952\n",
    "0.8641711229946524\n",
    "0.8695187165775401\n",
    "0.8673796791443851\n",
    "0.8663101604278075\n",
    "\n",
    "\n",
    "0.8673796791443851\n",
    "    \n",
    "0.6186332767402377\n",
    "\n",
    "\n",
    "-------------------tdidf\n",
    "---------------- \n",
    "num_generations = 50    \n",
    "sol_per_pop = 100 # Population size.\n",
    "num_parents_mating = 50 # Number of parents inside the mating pool.\n",
    "num_mutations = 3 # Number of elements to mutate.\n",
    "result: 0.8673796791443851\n",
    "    \n",
    "---------------- \n",
    "num_generations = 50      \n",
    "sol_per_pop = 100 # Population size.\n",
    "num_parents_mating = 50 # Number of parents inside the mating pool.\n",
    "num_mutations = 3 # Number of elements to mutate.\n",
    "0.8695187165775401\n",
    "---------------- \n",
    "num_generations = 50  \n",
    "sol_per_pop = 200 # Population size.\n",
    "num_parents_mating = 50 # Number of parents inside the mating pool.\n",
    "num_mutations = 3 # Number of elements to mutate.\n",
    "0.8663101604278075\n",
    "---------------- \n",
    "num_generations = 100\n",
    "sol_per_pop = 200 # Population size.\n",
    "num_parents_mating = 50 # Number of parents inside the mating pool.\n",
    "num_mutations = 3 # Number of elements to mutate.\n",
    "0.8695187165775401\n",
    "---------------- \n",
    "num_generations = 100\n",
    "sol_per_pop = 200 # Population size.\n",
    "num_parents_mating = 50 # Number of parents inside the mating pool.\n",
    "num_mutations = 3 # Number of elements to mutate.\n",
    "0.8673796791443851\n",
    "---------------- \n",
    "num_generations = 100\n",
    "sol_per_pop = 300 # Population size.\n",
    "num_parents_mating = 50 # Number of parents inside the mating pool.\n",
    "num_mutations = 3 # Number of elements to mutate.\n",
    "0.8737967914438503\n",
    "----------------\n",
    "num_generations = 100\n",
    "sol_per_pop = 300 # Population size.\n",
    "num_parents_mating = 100 # Number of parents inside the mating pool.\n",
    "num_mutations = 3 # Number of elements to mutate.\n",
    "0.8663101604278075\n",
    "----------------\n",
    "num_generations = 100\n",
    "sol_per_pop = 300 # Population size.\n",
    "num_parents_mating = 100 # Number of parents inside the mating pool.\n",
    "num_mutations = 3 # Number of elements to mutate.\n",
    "0.8737967914438503\n",
    "----------------\n",
    "num_generations = 100\n",
    "sol_per_pop = 300 # Population size.\n",
    "num_parents_mating = 30 # Number of parents inside the mating pool.\n",
    "num_mutations = 3 # Number of elements to mutate.\n",
    "0.8673796791443851\n",
    "\n",
    "0.8695187165775401\n",
    "----------------\n",
    "num_generations = 100\n",
    "sol_per_pop = 300 # Population size.\n",
    "num_parents_mating = 150 # Number of parents inside the mating pool.\n",
    "num_mutations = 3 # Number of elements to mutate.\n",
    "0.8684491978609625\n",
    "------------------\n",
    "num_generations = 100\n",
    "sol_per_pop = 500 # Population size.\n",
    "num_parents_mating = 100 # Number of parents inside the mating pool.\n",
    "num_mutations = 3 # Number of elements to mutate.\n",
    "0.8695187165775401\n",
    "------------------\n",
    "num_generations = 100\n",
    "sol_per_pop = 500 # Population size.\n",
    "num_parents_mating = 200 # Number of parents inside the mating pool.\n",
    "num_mutations = 3 # Number of elements to mutate.\n",
    "0.8759358288770054\n",
    "----------------\n",
    "sol_per_pop = 500 # Population size.\n",
    "num_parents_mating = 200 # Number of parents inside the mating pool.\n",
    "num_mutations = 3 # Number of elements to mutate.\n",
    "0.8759358288770054\n",
    "------------------\n",
    "num_generations = 100\n",
    "sol_per_pop = 500 # Population size.\n",
    "num_parents_mating = 200 # Number of parents inside the mating pool.\n",
    "num_mutations = 30 # Number of elements to mutate.\n",
    "0.8748663101604278\n",
    "------------------\n",
    "num_generations = 100\n",
    "sol_per_pop = 500 # Population size.\n",
    "num_parents_mating = 200 # Number of parents inside the mating pool.\n",
    "num_mutations = 30 # Number of elements to mutate.\n",
    "0.8748663101604278\n",
    "------------------\n",
    "num_generations = 100\n",
    "sol_per_pop = 900 # Population size.\n",
    "num_parents_mating = 250 # Number of parents inside the mating pool.\n",
    "num_mutations = 3 # Number of elements to mutate.\n",
    "0.8770053475935828"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-80d82d2aa2ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# (sublinear_tf=True, max_df=0.3, stop_words='english',smooth_idf =True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdataset_train_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mdataset_test_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset_train' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "# (sublinear_tf=True, max_df=0.3, stop_words='english',smooth_idf =True)\n",
    "\n",
    "dataset_train_vectors = vectorizer.fit_transform(dataset_train.data)\n",
    "dataset_test_vectors = vectorizer.transform(dataset_test.data) \n",
    "\n",
    "Xtr = dataset_train_vectors\n",
    "ytr = dataset_train.target\n",
    "Xtt = dataset_test_vectors\n",
    "ytt = dataset_test.target\n",
    "\n",
    "# Instantiate the estimator\n",
    "clf_MNB = MultinomialNB(alpha=0.3, class_prior=None, fit_prior=True)\n",
    "\n",
    "# Fit the model with data (aka \"model training\")\n",
    "clf_MNB.fit(Xtr, ytr)\n",
    "\n",
    "# Predict the response for a new observation\n",
    "y_pred_mnb = clf_MNB.predict(Xtt)\n",
    "# print (\"Predicted Class Labels:\",y_pred_mnb)\n",
    "\n",
    "# calculate accuracy\n",
    "print (\"Classification Accuracy:\",metrics.accuracy_score(ytt, y_pred_mnb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class Labels: [1 2 1 ... 1 3 3]\n",
      "Classification Accuracy: 0.856760374832664\n",
      "MultinomialNB 10-Cross Validation : 0.9187038860806073\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cats =['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware']\n",
    "\n",
    "dataset_train = fetch_20newsgroups(subset='train', categories=cats)\n",
    "dataset_test = fetch_20newsgroups(subset='test', categories=cats)\n",
    "data = fetch_20newsgroups(subset='all', categories=cats)\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "# TfidfVectorizer(sublinear_tf=True, max_df=0.3, stop_words='english',smooth_idf =True)\n",
    "\n",
    "dataset_train_vectors = vectorizer.fit_transform(dataset_train.data)\n",
    "dataset_test_vectors = vectorizer.transform(dataset_test.data) \n",
    "dataset_vectors = vectorizer.fit_transform(data.data)\n",
    "yy = data.target\n",
    "XX = dataset_vectors\n",
    "\n",
    "Xtr = dataset_train_vectors\n",
    "ytr = dataset_train.target\n",
    "Xtt = dataset_test_vectors\n",
    "ytt = dataset_test.target\n",
    "\n",
    "# Instantiate the estimator\n",
    "clf_MNB = MultinomialNB(alpha=0.3, class_prior=None, fit_prior=True)\n",
    "\n",
    "# Fit the model with data (aka \"model training\")\n",
    "clf_MNB.fit(Xtr, ytr)\n",
    "\n",
    "# Predict the response for a new observation\n",
    "y_pred_mnb = clf_MNB.predict(Xtt)\n",
    "print (\"Predicted Class Labels:\",y_pred_mnb)\n",
    "\n",
    "# calculate accuracy\n",
    "print (\"Classification Accuracy:\",metrics.accuracy_score(ytt, y_pred_mnb))\n",
    "y_pred_mnb = clf_MNB.predict(Xtt)\n",
    "# print (\"Predicted Class Labels:\",y_pred_mnb)\n",
    "\n",
    "\n",
    "print (\"MultinomialNB 10-Cross Validation :\",cross_val_score(clf_MNB, XX, yy, cv=5, scoring='accuracy').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TfidfVectorizer:\n",
    "Classification Accuracy: 0.856760374832664\n",
    "Predicted Class Labels: [1 2 1 ... 1 3 3]\n",
    "MultinomialNB 10-Cross Validation : 0.9187038860806073"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol_per_pop = 20: 0.5952886247877759\n",
    "----------------------\n",
    "sol_per_pop = 8 # Population size.\n",
    "num_parents_mating = 4 # Number of parents inside the mating pool.\n",
    "num_mutations = 3 # Number of elements to mutate.\n",
    "num_generations = 100\n",
    "result:0.5988964346349746\n",
    "---------------------\n",
    "sol_per_pop = 200 # Population size.\n",
    "num_parents_mating = 4 # Number of parents inside the mating pool.\n",
    "num_mutations = 3 # Number of elements to mutate.\n",
    "num_generations = 100\n",
    "result:0.6050509337860781\n",
    "---------------------\n",
    "result:0.6118421052631579\n",
    "--------------------- ✔️\n",
    "num_generations = 100\n",
    "sol_per_pop = 50 # Population size. ✔️\n",
    "num_parents_mating = 4 # Number of parents inside the mating pool.\n",
    "num_mutations = 3 # Number of elements to mutate.\n",
    "results:0.6169354838709677\n",
    "--------------------- \n",
    "num_generations = 100\n",
    "sol_per_pop = 20 # Population size.\n",
    "num_parents_mating = 4 # Number of parents inside the mating pool.\n",
    "num_mutations = 3 # Number of elements to mutate.\n",
    "results:0.6143887945670629\n",
    "---------------------\n",
    "num_generations = 100\n",
    "sol_per_pop = 20 # Population size.\n",
    "num_parents_mating = 10 # Number of parents inside the mating pool.\n",
    "num_mutations = 3 # Number of elements to mutate.\n",
    "result: 0.6137521222410866\n",
    "---------------------\n",
    "num_generations = 100\n",
    "sol_per_pop = 50 # Population size.\n",
    "num_parents_mating = 25 # Number of parents inside the mating pool.\n",
    "num_mutations = 3 # Number of elements to mutate.\n",
    "result:0.6177843803056027\n",
    "---------------------\n",
    "num_generations = 50\n",
    "sol_per_pop = 500 # Population size.\n",
    "num_parents_mating = 250 # Number of parents inside the mating pool.\n",
    "num_mutations = 3 # Number of elements to mutate.\n",
    "result:0.62330220713073\n",
    "--------------------\n",
    "num_generations = 50\n",
    "sol_per_pop = 500 # Population size.\n",
    "num_parents_mating = 250 # Number of parents inside the mating pool.\n",
    "num_mutations = 30 # Number of elements to mutate.\n",
    "result: 0.6205432937181664\n",
    "--------------------\n",
    "num_generations = 50\n",
    "sol_per_pop = 5000 # Population size.\n",
    "num_parents_mating = 2500 # Number of parents inside the mating pool.\n",
    "num_mutations = 10 # Number of elements to mutate.\n",
    "result: 0.6226655348047538\n",
    "    \n",
    "------------------\n",
    "------------------\n",
    "num_generations = 50\n",
    "sol_per_pop = 1000 # Population size.\n",
    "num_parents_mating = 600 # Number of parents inside the mating pool.\n",
    "num_mutations = 3 # Number of elements to mutate.\n",
    "resultt: 0.8434163701067615\n",
    "------------------\n",
    "num_generations = 50\n",
    "sol_per_pop = 1000 # Population size.\n",
    "num_parents_mating = 500 # Number of parents inside the mating pool.\n",
    "num_mutations = 3 # Number of elements to mutate.\n",
    "resultt: 0.0.8380782918149466\n",
    "------------------\n",
    "num_generations = 50\n",
    "sol_per_pop = 500 # Population size.\n",
    "num_parents_mating = 250 # Number of parents inside the mating pool.\n",
    "num_mutations = 3 # Number of elements to mutate.\n",
    "resultt: 0.0.8380782918149466    \n",
    "0.8416370106761566\n",
    "------------------\n",
    "num_generations = 50\n",
    "sol_per_pop = 100 # Population size.\n",
    "num_parents_mating = 50 # Number of parents inside the mating pool.\n",
    "num_mutations = 3 # Number of elements to mutate.\n",
    "result: 0.8416370106761566\n",
    "------------------\n",
    "num_generations = 50\n",
    "sol_per_pop = 100 # Population size.\n",
    "num_parents_mating = 25 # Number of parents inside the mating pool.\n",
    "num_mutations = 3 # Number of elements to mutate.\n",
    "------------------\n",
    "num_generations = 50\n",
    "sol_per_pop = 50 # Population size.\n",
    "num_parents_mating = 25 # Number of parents inside the mating pool.\n",
    "num_mutations = 3 # Number of elements to mutate.\n",
    "result:0.8673796791443851\n",
    "------------------\n",
    "num_generations = 50    \n",
    "sol_per_pop = 500 # Population size.\n",
    "num_parents_mating = 10 # Number of parents inside the mating pool.\n",
    "num_mutations = 3 # Number of elements to mutate.\n",
    "result: 0.8641711229946524\n",
    "0.8695187165775401\n",
    "------------------\n",
    "num_generations = 50 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
