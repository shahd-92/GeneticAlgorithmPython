{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import sklearn.svm\n",
    "import numpy as np\n",
    "\n",
    "def reduce_features(solution, features):\n",
    "    selected_elements_indices = numpy.where(solution == 1)[0]\n",
    "    reduced_features = features[:, selected_elements_indices]\n",
    "    return reduced_features\n",
    "\n",
    "\n",
    "def classification_accuracy(labels, predictions):\n",
    "    correct = numpy.where(labels == predictions)[0]\n",
    "    accuracy = correct.shape[0]/labels.shape[0]\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def cal_pop_fitness(pop, features, labels, train_indices, test_indices):\n",
    "    accuracies = numpy.zeros(pop.shape[0])\n",
    "    idx = 0\n",
    "\n",
    "    for curr_solution in pop:\n",
    "        reduced_features = reduce_features(curr_solution, features)\n",
    "        train_data = reduced_features[train_indices, :]\n",
    "        test_data = reduced_features[test_indices, :]\n",
    "        print (\"train_indices::: \", train_indices)\n",
    "        print (\"labels[train_indices] : \", labels[train_indices])\n",
    "        train_labels = labels[train_indices]\n",
    "        test_labels = labels[test_indices]\n",
    "\n",
    "        SV_classifier = sklearn.svm.SVC(gamma='scale')\n",
    "        SV_classifier.fit(X=train_data, y=train_labels)\n",
    "\n",
    "        predictions = SV_classifier.predict(test_data)\n",
    "        accuracies[idx] = classification_accuracy(test_labels, predictions)\n",
    "        idx = idx + 1\n",
    "    return accuracies\n",
    "\n",
    "def select_mating_pool(pop, fitness, num_parents):\n",
    "    # Selecting the best individuals in the current generation as parents for producing the offspring of the next generation.\n",
    "    parents = numpy.empty((num_parents, pop.shape[1]))\n",
    "    for parent_num in range(num_parents):\n",
    "        max_fitness_idx = numpy.where(fitness == numpy.max(fitness))\n",
    "        max_fitness_idx = max_fitness_idx[0][0]\n",
    "        parents[parent_num, :] = pop[max_fitness_idx, :]\n",
    "        fitness[max_fitness_idx] = -99999999999\n",
    "    return parents\n",
    "\n",
    "\n",
    "def crossover(parents, offspring_size):\n",
    "    offspring = numpy.empty(offspring_size)\n",
    "    # The point at which crossover takes place between two parents. Usually, it is at the center.\n",
    "    crossover_point = numpy.uint8(offspring_size[1]/2)\n",
    "\n",
    "    for k in range(offspring_size[0]):\n",
    "        # Index of the first parent to mate.\n",
    "        parent1_idx = k%parents.shape[0]\n",
    "        # Index of the second parent to mate.\n",
    "        parent2_idx = (k+1)%parents.shape[0]\n",
    "        # The new offspring will have its first half of its genes taken from the first parent.\n",
    "        offspring[k, 0:crossover_point] = parents[parent1_idx, 0:crossover_point]\n",
    "        # The new offspring will have its second half of its genes taken from the second parent.\n",
    "        offspring[k, crossover_point:] = parents[parent2_idx, crossover_point:]\n",
    "    return offspring\n",
    "\n",
    "\n",
    "def mutation(offspring_crossover, num_mutations=2):\n",
    "    mutation_idx = numpy.random.randint(low=0, high=offspring_crossover.shape[1], size=num_mutations)\n",
    "    # Mutation changes a single gene in each offspring randomly.\n",
    "    for idx in range(offspring_crossover.shape[0]):\n",
    "        # The random value to be added to the gene.\n",
    "        offspring_crossover[idx, mutation_idx] = 1 - offspring_crossover[idx, mutation_idx]\n",
    "    return offspring_crossover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer , CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "# from sklearn.datasets import fetch_20newsgroups_vectorized \n",
    "\n",
    "twenty_train = fetch_20newsgroups(subset='train', shuffle=True)\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(twenty_train.data).toarray()\n",
    "print (len(twenty_train.data))\n",
    "print (X_train_counts.shape)\n",
    "# twenty_train.data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X = vectorizer.fit_transform(newsgroups_train.data)\n",
    "y = newsgroups_train.target\n",
    "Xtest = vectorizer.transform(newsgroups_test.data)\n",
    "ytest = newsgroups_test.target\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "# import GA\n",
    "import pickle\n",
    "import matplotlib.pyplot\n",
    "\n",
    "newsgroups = fetch_20newsgroups(subset='all')\n",
    "categories = list(newsgroups.target_names)\n",
    "newsgroups_train = fetch_20newsgroups(subset='train',categories=categories)\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', categories=categories)\n",
    "\n",
    "# f = open(\"dataset_features.pkl\", \"rb\")\n",
    "data_inputs = newsgroups_train.data\n",
    "# f.close()\n",
    "\n",
    "# f = open(\"outputs.pkl\", \"rb\")\n",
    "data_outputs = categories\n",
    "# f.close()\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(twenty_train.data)\n",
    "data_inputs = X_train_counts\n",
    "num_samples = data_inputs.shape[0]\n",
    "num_feature_elements = data_inputs.shape[1]\n",
    "\n",
    "train_indices = numpy.arange(1, num_samples, 4)\n",
    "print (\"train_indices: \" , train_indices)\n",
    "test_indices = numpy.arange(0, num_samples, 4)\n",
    "print(\"Number of training samples: \", train_indices.shape[0])\n",
    "print(\"Number of test samples: \", test_indices.shape[0])\n",
    "\n",
    "\"\"\"\n",
    "Genetic algorithm parameters:\n",
    "    Population size\n",
    "    Mating pool size\n",
    "    Number of mutations\n",
    "\"\"\"\n",
    "sol_per_pop = 8 # Population size.\n",
    "num_parents_mating = 4 # Number of parents inside the mating pool.\n",
    "num_mutations = 3 # Number of elements to mutate.\n",
    "\n",
    "# Defining the population shape.\n",
    "pop_shape = (sol_per_pop, num_feature_elements)\n",
    "\n",
    "# Creating the initial population.\n",
    "new_population = numpy.random.randint(low=0, high=2, size=pop_shape)\n",
    "print(new_population.shape)\n",
    "\n",
    "best_outputs = []\n",
    "num_generations = 100\n",
    "for generation in range(num_generations):\n",
    "    print(\"Generation : \", generation)\n",
    "    # Measuring the fitness of each chromosome in the population.\n",
    "    print (\"data_outputs: \" , data_outputs)\n",
    "    fitness = cal_pop_fitness(new_population, data_inputs, data_outputs, train_indices, test_indices)\n",
    "\n",
    "    best_outputs.append(numpy.max(fitness))\n",
    "    # The best result in the current iteration.\n",
    "    print(\"Best result : \", best_outputs[-1])\n",
    "\n",
    "    # Selecting the best parents in the population for mating.\n",
    "    parents = GA.select_mating_pool(new_population, fitness, num_parents_mating)\n",
    "\n",
    "    # Generating next generation using crossover.\n",
    "    offspring_crossover = GA.crossover(parents, offspring_size=(pop_shape[0]-parents.shape[0], num_feature_elements))\n",
    "\n",
    "    # Adding some variations to the offspring using mutation.\n",
    "    offspring_mutation = GA.mutation(offspring_crossover, num_mutations=num_mutations)\n",
    "\n",
    "    # Creating the new population based on the parents and offspring.\n",
    "    new_population[0:parents.shape[0], :] = parents\n",
    "    new_population[parents.shape[0]:, :] = offspring_mutation\n",
    "\n",
    "# Getting the best solution after iterating finishing all generations.\n",
    "# At first, the fitness is calculated for each solution in the final generation.\n",
    "fitness = GA.cal_pop_fitness(new_population, data_inputs, data_outputs, train_indices, test_indices)\n",
    "# Then return the index of that solution corresponding to the best fitness.\n",
    "best_match_idx = numpy.where(fitness == numpy.max(fitness))[0]\n",
    "best_match_idx = best_match_idx[0]\n",
    "\n",
    "best_solution = new_population[best_match_idx, :]\n",
    "best_solution_indices = numpy.where(best_solution == 1)[0]\n",
    "best_solution_num_elements = best_solution_indices.shape[0]\n",
    "best_solution_fitness = fitness[best_match_idx]\n",
    "\n",
    "print(\"best_match_idx : \", best_match_idx)\n",
    "print(\"best_solution : \", best_solution)\n",
    "print(\"Selected indices : \", best_solution_indices)\n",
    "print(\"Number of selected elements : \", best_solution_num_elements)\n",
    "print(\"Best solution fitness : \", best_solution_fitness)\n",
    "\n",
    "matplotlib.pyplot.plot(best_outputs)\n",
    "matplotlib.pyplot.xlabel(\"Iteration\")\n",
    "matplotlib.pyplot.ylabel(\"Fitness\")\n",
    "matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print (num_samples)\n",
    "# print (train_indices)\n",
    "newsgroups_train.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (X_train_counts)\n",
    "print (X_train_counts.shape[0])\n",
    "In [274]: dt=np.dtype('int,float')\n",
    "\n",
    "In [275]: np.array(xlist,dtype=dt)\n",
    "# data_inputs = np.array(X_train_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (dataset.data[1])\n",
    "print (dataset.target[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dataframe path, population number and generation number from command-line argument\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups_vectorized\n",
    "# newsgroups = fetch_20newsgroups_vectorized(subset='all')\n",
    "# newsgroups = fetch_20newsgroups_vectorized(subset='test')\n",
    "newsgroups = fetch_20newsgroups_vectorized(subset='train')\n",
    "\n",
    "categories = list(newsgroups.target_names)\n",
    "dataframePath = newsgroups\n",
    "n_pop = 20\n",
    "n_gen = 4\n",
    "\n",
    "# read dataframe from csv\n",
    "df = newsgroups\n",
    "\n",
    "# encode labels column to numbers\n",
    "le = categories\n",
    "le.fit(df.iloc[:, -1])\n",
    "y = le.transform(df.iloc[:, -1])\n",
    "X = categories\n",
    "\n",
    "# get accuracy with all features\n",
    "individual = [1 for i in range(len(X.columns))]\n",
    "print(\"Accuracy with all features: \\t\" +\n",
    "      str(getFitness(individual, X, y)) + \"\\n\")\n",
    "\n",
    "# apply genetic algorithm\n",
    "hof = geneticAlgorithm(X, y, n_pop, n_gen)\n",
    "\n",
    "# select the best individual\n",
    "accuracy, individual, header = bestIndividual(hof, X, y)\n",
    "print('Best Accuracy: \\t' + str(accuracy))\n",
    "print('Number of Features in Subset: \\t' + str(individual.count(1)))\n",
    "print('Individual: \\t\\t' + str(individual))\n",
    "print('Feature Subset\\t: ' + str(header))\n",
    "\n",
    "print('\\n\\ncreating a new classifier with the result')\n",
    "\n",
    "# read dataframe from csv one more time\n",
    "# df = pd.read_csv(dataframePath, sep=',')\n",
    "\n",
    "# with feature subset\n",
    "X = df[header]\n",
    "\n",
    "clf = LogisticRegression()\n",
    "\n",
    "scores = cross_val_score(clf, X, y, cv=5)\n",
    "print(\"Accuracy with Feature Subset: \\t\" + str(avg(scores)) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from deap import creator, base, tools, algorithms\n",
    "import sys\n",
    "\n",
    "\n",
    "def avg(l):\n",
    "    \"\"\"\n",
    "    Returns the average between list elements\n",
    "    \"\"\"\n",
    "    return (sum(l)/float(len(l)))\n",
    "\n",
    "\n",
    "def getFitness(individual, X, y):\n",
    "    \"\"\"\n",
    "    Feature subset fitness function\n",
    "    \"\"\"\n",
    "\n",
    "    if(individual.count(0) != len(individual)):\n",
    "        # get index with value 0\n",
    "        cols = [index for index in range(\n",
    "            len(individual)) if individual[index] == 0]\n",
    "\n",
    "        # get features subset\n",
    "        X_parsed = X.drop(X.columns[cols], axis=1)\n",
    "        X_subset = pd.get_dummies(X_parsed)\n",
    "\n",
    "        # apply classification algorithm\n",
    "        clf = LogisticRegression()\n",
    "\n",
    "        return (avg(cross_val_score(clf, X_subset, y, cv=5)),)\n",
    "    else:\n",
    "        return(0,)\n",
    "\n",
    "\n",
    "def geneticAlgorithm(X, y, n_population, n_generation):\n",
    "    \"\"\"\n",
    "    Deap global variables\n",
    "    Initialize variables to use eaSimple\n",
    "    \"\"\"\n",
    "    # create individual\n",
    "    creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "    creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "\n",
    "    # create toolbox\n",
    "    toolbox = base.Toolbox()\n",
    "    toolbox.register(\"attr_bool\", random.randint, 0, 1)\n",
    "    toolbox.register(\"individual\", tools.initRepeat,\n",
    "                     creator.Individual, toolbox.attr_bool, len(X.columns))\n",
    "    toolbox.register(\"population\", tools.initRepeat, list,\n",
    "                     toolbox.individual)\n",
    "    toolbox.register(\"evaluate\", getFitness, X=X, y=y)\n",
    "    toolbox.register(\"mate\", tools.cxOnePoint)\n",
    "    toolbox.register(\"mutate\", tools.mutFlipBit, indpb=0.05)\n",
    "    toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "\n",
    "    # initialize parameters\n",
    "    pop = toolbox.population(n=n_population)\n",
    "    hof = tools.HallOfFame(n_population * n_generation)\n",
    "    stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "    stats.register(\"avg\", np.mean)\n",
    "    stats.register(\"min\", np.min)\n",
    "    stats.register(\"max\", np.max)\n",
    "\n",
    "    # genetic algorithm\n",
    "    pop, log = algorithms.eaSimple(pop, toolbox, cxpb=0.5, mutpb=0.2,\n",
    "                                   ngen=n_generation, stats=stats, halloffame=hof,\n",
    "                                   verbose=True)\n",
    "\n",
    "    # return hall of fame\n",
    "    return hof\n",
    "\n",
    "\n",
    "def bestIndividual(hof, X, y):\n",
    "    \"\"\"\n",
    "    Get the best individual\n",
    "    \"\"\"\n",
    "    maxAccurcy = 0.0\n",
    "    for individual in hof:\n",
    "        if(individual.fitness.values > maxAccurcy):\n",
    "            maxAccurcy = individual.fitness.values\n",
    "            _individual = individual\n",
    "\n",
    "    _individualHeader = [list(X)[i] for i in range(\n",
    "        len(_individual)) if _individual[i] == 1]\n",
    "    return _individual.fitness.values, _individual, _individualHeader\n",
    "\n",
    "\n",
    "def getArguments():\n",
    "    \"\"\"\n",
    "    Get argumments from command-line\n",
    "    If pass only dataframe path, pop and gen will be default\n",
    "    \"\"\"\n",
    "    dfPath = sys.argv[1]\n",
    "    if(len(sys.argv) == 4):\n",
    "        pop = int(sys.argv[2])\n",
    "        gen = int(sys.argv[3])\n",
    "    else:\n",
    "        pop = 10\n",
    "        gen = 2\n",
    "    return dfPath, pop, gen\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer , CountVectorizer , HashingVectorizer\n",
    "from sklearn.datasets import fetch_20newsgroups_vectorized\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "import pandas as pd\n",
    "# newsgroups = fetch_20newsgroups_vectorized(subset='all')\n",
    "# newsgroups = fetch_20newsgroups_vectorized(subset='test')\n",
    "newsgroups = fetch_20newsgroups_vectorized(subset='train')\n",
    "\n",
    "SEED = 2018\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "#==============================================================================\n",
    "# Data \n",
    "#==============================================================================\n",
    "dataset = newsgroups\n",
    "\n",
    "\n",
    "#==============================================================================\n",
    "# CV MSE before feature selection\n",
    "#==============================================================================\n",
    "# est = LinearRegression()\n",
    "\n",
    "categories = None\n",
    "# data_train = fetch_20newsgroups_vectorized(subset='train', remove=('headers', 'footers', 'quotes'))\n",
    "# data_test = fetch_20newsgroups_vectorized(subset='test', remove=('headers', 'footers', 'quotes'))\n",
    "# data_all = fetch_20newsgroups_vectorized(subset='all', remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "# store training feature matrix in \"Xtr\"\n",
    "# Xtr = data_train.data\n",
    "# print (\"Xtr:\\n\", Xtr)\n",
    "\n",
    "# store training response vector in \"ytr\"\n",
    "# ytr = data_train.target\n",
    "# print (\"ytr:\",ytr)\n",
    "\n",
    "# store testing feature matrix in \"Xtt\"\n",
    "# Xtt = data_train.data\n",
    "# print (\"Xtt:\\n\", Xtt)\n",
    "\n",
    "# store testing response vector in \"ytt\"\n",
    "# ytt = data_train.target\n",
    "# print (\"ytt:\",ytt)\n",
    "\n",
    "# store all feature matrix in \"Xtr\"\n",
    "# X = data_all.data\n",
    "# print (\"X:\\n\", X.shape)\n",
    "\n",
    "# store training response vector in \"ytr\"\n",
    "# y = data_all.target\n",
    "# print (\"ytr:\",ytr)\n",
    "\n",
    "categories = ['alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space']\n",
    "\n",
    "# data = fetch_20newsgroups(subset='all')\n",
    "data_train = fetch_20newsgroups(subset='train',  categories=categories, remove=('headers', 'footers', 'quotes'))\n",
    "data_test = fetch_20newsgroups(subset='test', categories=categories, remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "y_train, y_test = data_train.target, data_test.target\n",
    "vectorizer = HashingVectorizer(stop_words='english', non_negative=True)\n",
    "X_train = vectorizer.transform(data_train.data)\n",
    "X_test = vectorizer.transform(data_test.data)\n",
    "\n",
    "#----------\n",
    "clf = MultinomialNB(alpha=.01)\n",
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_test)\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "print(\"accuracy before feature selection:   %0.3f\" % score)\n",
    "#---------\n",
    "\n",
    "# vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.3, stop_words='english',smooth_idf =True)\n",
    "# data_train_vectors = vectorizer.fit_transform(data_train.data)\n",
    "# # data_test_vectors = vectorizer.transform(data_test.data) \n",
    "# X = data_train_vectors\n",
    "# y = data_train.target\n",
    "\n",
    "\n",
    "# --------------------------------------\n",
    "\n",
    "# Xtt = data_test_vectors\n",
    "# ytt = data_test.target\n",
    "\n",
    "# clf_mnb = MultinomialNB(alpha=.01)\n",
    "# clf_mnb.fit(X, y)\n",
    "# y_pred_mnb = clf_mnb.predict(Xtt)\n",
    "# print (\"Classification Accuracy:\",metrics.accuracy_score(ytt, y_pred_mnb))\n",
    "# --------------------------------------\n",
    "# clf_mnb = MultinomialNB(alpha=.01)\n",
    "## print (\"MultinomialNB 10-Cross Validation Score before feature selection:\",cross_val_score(clf_mnb, X, y, cv=5, scoring='accuracy').mean())\n",
    "\n",
    "# pred = clf_mnb.predict(Xtr)\n",
    "# m = metrics.f1_score(ytr, pred, average='macro')\n",
    "# print(\"CV metrics f1 before feature selection: {:.2f}\".format(m))\n",
    "#     score = cross_validation.cross_val_score( clf, X.toarray(), y, cv=5)\n",
    "# score = -1.0 * cross_val_score(clf_mnb, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "# print(\"CV MSE before feature selection: {:.2f}\".format(np.mean(score)))\n",
    "\n",
    "#==============================================================================\n",
    "# Class performing feature selection with genetic algorithm\n",
    "#==============================================================================\n",
    "# (estimator=clf_mnb, n_gen=4, size=50, n_best=10, n_rand=40, n_children=2, mutation_rate=0.05)\n",
    "class GeneticSelector():\n",
    "    def __init__(self, estimator, n_gen, size, n_best, n_rand, \n",
    "                 n_children, mutation_rate):\n",
    "        \n",
    "        print (\"__init__: \")\n",
    "        # Estimator \n",
    "        self.estimator = estimator\n",
    "        # Number of generations\n",
    "        self.n_gen = n_gen\n",
    "        # Number of chromosomes in population\n",
    "        self.size = size\n",
    "        # Number of best chromosomes to select\n",
    "        self.n_best = n_best\n",
    "        # Number of random chromosomes to select\n",
    "        self.n_rand = n_rand\n",
    "        # Number of children created during crossover\n",
    "        self.n_children = n_children\n",
    "        # Probablity of chromosome mutation\n",
    "        self.mutation_rate = mutation_rate\n",
    "        if int((self.n_best + self.n_rand) / 2) * self.n_children != self.size:\n",
    "            raise ValueError(\"The population size is not stable.\")  \n",
    "            \n",
    "# ------------------------------\n",
    "# i :  0\n",
    "# chromosome shape:  (101631,)\n",
    "# mask:  [False  True False ... False False False]\n",
    "# mask shape:  (101631,)\n",
    "# chromosome[mask]:  [False False False ... False False False]\n",
    "# chromosome[mask] shape:  (30494,)71082 10329\n",
    "\n",
    "# i :  0\n",
    "# chromosome shape:  (101631,)\n",
    "# np.random.rand(len(chromosome)):  [0.96728762 0.29321817 0.06291302 ... 0.09776348 0.70959122 0.86756446]\n",
    "# np.random.rand(len(chromosome)) < 0.3:  [False False False ... False  True False]\n",
    "# mask:  [False False False ... False False False]\n",
    "# mask [mask !=False]) :  [ True  True  True ...  True  True  True]\n",
    "# mask shape:  (101631,)\n",
    "# chromosome[mask]:  [False False False ... False False False]\n",
    "# chromosome:  (101631,)\n",
    "# chromosome[mask] shape:  (5047,)\n",
    "\n",
    "# i :  0\n",
    "# chromosome shape:  (101631,)\n",
    "# chromosome[chromosome !=False] :  (101631,)\n",
    "# mask [mask !=False]) :  (5047,)\n",
    "# mask shape:  (101631,)\n",
    "# (chromosome[mask]!=False).shape:  (5047,)\n",
    "# chromosome[mask]:  [False False False ... False False False]\n",
    "# chromosome:  (101631,)\n",
    "# chromosome[mask] shape:  (5047,)\n",
    "# chromosome[chromosome !=False] :  (96584,)\n",
    "    \n",
    "# ------------------------------\n",
    "    def initilize(self):\n",
    "#         print (\"initilize: \")\n",
    "        population = []\n",
    "        for i in range(self.size):\n",
    "            chromosome = np.ones(self.n_features, dtype=np.bool)\n",
    "            # each chromosome has 113000 size /  chromosome is document / pop = 100 chromosome\n",
    "#             print (\"self.n_features: \", self.n_features)\n",
    "#             print (\"chromosome shape: \", chromosome.shape)\n",
    "#             print (\"chromosome[chromosome !=False] : \", chromosome[chromosome !=False].shape)\n",
    "    \n",
    "            mask = np.random.rand(len(chromosome)) < 0.3  # Create an array of the given shape and populate it with random samples\n",
    "            \n",
    "#             print (\"mask [mask !=False]) : \", mask[mask !=False].shape)\n",
    "#             print (\"mask shape: \", mask.shape)\n",
    "            \n",
    "            chromosome[mask] = False\n",
    "#             print (\"(chromosome[mask]!=False).shape: \", (chromosome[mask]!=False).shape)\n",
    "#             print (\"chromosome[mask]: \", chromosome[mask])\n",
    "            \n",
    "#             print (\"chromosome: \", chromosome.shape)\n",
    "#             print (\"chromosome[mask] shape: \", chromosome[mask].shape)\n",
    "#             print (\"chromosome[chromosome !=False] : \", chromosome[chromosome !=False].shape)\n",
    "            population.append(chromosome)\n",
    "#             print (\"population: \", population)\n",
    "        return population\n",
    "\n",
    "    def fitness(self, population):\n",
    "#         print (\"fitness: \")\n",
    "        X, y = self.dataset\n",
    "#         print (\"X: \",X)\n",
    "#         print (\"X.shape: \",X.shape)\n",
    "#         print (\"y.shape: \",y.shape)\n",
    "        scores = []\n",
    "        for chromosome in population:\n",
    "#             print (\"chromosome: \",chromosome)\n",
    "#             print (\"chromosome.shape: \",chromosome.shape)\n",
    "#             print (\"chromosome[chromosome !=False].shape: \",chromosome[chromosome !=False].shape)\n",
    "#             print (\"X[:,chromosome]: \",X[:,chromosome])\n",
    "#             print (\"X[:,].shape: \",X[:,].shape)\n",
    "#             print (\"X[,].shape: \",X[0,].shape)\n",
    "#             score = X[:,chromosome].mean()\n",
    "            score = -1.0 * np.mean(cross_val_score(self.estimator, X[:,chromosome], y, cv=5, scoring=\"neg_mean_squared_error\"))\n",
    "            scores.append(score)\n",
    "        \n",
    "#         print (\"scores.shape: \",len(scores))\n",
    "#         print (\"scores: \",scores)\n",
    "        scores, population = np.array(scores), np.array(population) \n",
    "        inds = np.argsort(scores)\n",
    "#         print (\"inds: \",inds)\n",
    "#         print(\"list(scores[inds]): \",list(scores[inds]))\n",
    "#         print(\"population[inds,:]: \",population[inds,:])\n",
    "#         print(\"list(population[inds,:]: \",list(population[inds,:]))\n",
    "        return list(scores[inds]), list(population[inds,:])\n",
    "\n",
    "    def select(self, population_sorted):\n",
    "#         print (\"select: \")\n",
    "        population_next = []\n",
    "        for i in range(self.n_best):\n",
    "            population_next.append(population_sorted[i])\n",
    "        for i in range(self.n_rand):\n",
    "            population_next.append(random.choice(population_sorted))\n",
    "        random.shuffle(population_next)\n",
    "        return population_next\n",
    "\n",
    "    def crossover(self, population):\n",
    "#         print (\"crossover: \")\n",
    "        population_next = []\n",
    "        for i in range(int(len(population)/2)):\n",
    "            for j in range(self.n_children):\n",
    "                chromosome1, chromosome2 = population[i], population[len(population)-1-i]\n",
    "                child = chromosome1\n",
    "                mask = np.random.rand(len(child)) > 0.5\n",
    "                child[mask] = chromosome2[mask]\n",
    "                population_next.append(child)\n",
    "#         print (len(population_next))\n",
    "        return population_next\n",
    "\t\n",
    "    def mutate(self, population):\n",
    "#         print (\"mutate: \")\n",
    "        population_next = []\n",
    "        for i in range(len(population)):\n",
    "            chromosome = population[i]\n",
    "            if random.random() < self.mutation_rate:\n",
    "                mask = np.random.rand(len(chromosome)) < 0.05\n",
    "                chromosome[mask] = False\n",
    "            population_next.append(chromosome)\n",
    "        return population_next\n",
    "\n",
    "    def generate(self, population):\n",
    "#         print (\"generate: \")\n",
    "        # Selection, crossover and mutation\n",
    "        scores_sorted, population_sorted = self.fitness(population)\n",
    "        population = self.select(population_sorted)\n",
    "        population = self.crossover(population)\n",
    "        population = self.mutate(population)\n",
    "        # History\n",
    "        self.chromosomes_best.append(population_sorted[0])\n",
    "        self.scores_best.append(scores_sorted[0])\n",
    "        self.scores_avg.append(np.mean(scores_sorted))\n",
    "        \n",
    "        return population\n",
    "\n",
    "    def fit(self, X, y):\n",
    "#         print (\"fit: \")\n",
    " \n",
    "        self.chromosomes_best = []\n",
    "        self.scores_best, self.scores_avg  = [], []\n",
    "        \n",
    "        self.dataset = X, y\n",
    "        self.n_features = X.shape[1]\n",
    "        # dfine number of features\n",
    "        self.n_features\n",
    "        population = self.initilize()  # 100 chromosome \n",
    "        for i in range(self.n_gen): # each pop generation has 4 \n",
    "            population = self.generate(population) \n",
    "#             XX.append(population)\n",
    "        return self \n",
    "    \n",
    "    @property\n",
    "    def support_(self):\n",
    "#         print (\"self.chromosomes_best[-1]: \",self.chromosomes_best[-1])\n",
    "        return self.chromosomes_best[-1]\n",
    "\n",
    "    def plot_scores(self):\n",
    "        plt.plot(self.scores_best, label='Best')\n",
    "        plt.plot(self.scores_avg, label='Average')\n",
    "        plt.legend()\n",
    "        plt.ylabel('Scores')\n",
    "        plt.xlabel('Generation')\n",
    "        plt.show()\n",
    "        \n",
    "\n",
    "\n",
    "# do2 = []\n",
    "# XX = []\n",
    "# for i in range(X.shape[0]//500):\n",
    "#     doc = X[i,]\n",
    "#     print (\"do1\",doc.shape)\n",
    "\n",
    "clf_mnb = MultinomialNB(alpha=.01) \n",
    "\n",
    "# XX = show_top10(clf_mnb, vectorizer, y)\n",
    "\n",
    "sel = GeneticSelector(estimator=clf_mnb,n_gen=7, size=200, n_best=40, n_rand=40, n_children=5, mutation_rate=0.05)\n",
    "\n",
    "sel.fit(X_train, y_train)\n",
    "#     print (XX[i])\n",
    "#     XX.append(population)\n",
    "#     for i in range(do.shape[1]):\n",
    "# #         if do[:,i] > 0:\n",
    "#         do2.append(do[:,i])\n",
    "#     #         print (\"feature \",X[0,i])\n",
    "#     print (\"do2\",doc.shape)\n",
    "#     do2 = []\n",
    "\n",
    "\n",
    "\n",
    "# XX.plot_scores()\n",
    "\n",
    "# print (len(XX))\n",
    "\n",
    "# --------------------------------------\n",
    "# clf_mnb = MultinomialNB(alpha=.1)\n",
    "\n",
    "# # Fit the model with data (aka \"model training\")\n",
    "# clf_mnb.fit(X[XX], y)\n",
    "\n",
    "# # Predict the response for a new observation\n",
    "# y_pred = clf_mnb.predict(Xt)\n",
    "# print (\"Predicted Class Labels:\",y_pred)\n",
    "\n",
    "# score = metrics.accuracy_score(yt, y_pred)\n",
    "# print(\"CV MSE before feature selection: {:.2f}\".format(score))\n",
    "# --------------------------------------\n",
    "\n",
    "#================\n",
    "clf = MultinomialNB(alpha=.01)\n",
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_test)\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "print(\"accuracy after feature selection:   %0.3f\" % score)\n",
    "#=================\n",
    "# 1048576\n",
    "\n",
    "# score = -1.0 * cross_val_score(clf_mnb, X[:,sel.support_], y, cv=5, scoring=\"neg_mean_squared_error\")\n",
    "# print(\"CV MSE after feature selection: {:.2f}\".format(np.mean(score))) \n",
    "# print (\"MultinomialNB 10-Cross Validation Score before feature selection:\",cross_val_score(clf_mnb, XX, y, cv=5, scoring='accuracy').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV MSE before feature selection: 3.98\n",
    "__init__: \n",
    "CV MSE after feature selection: 4.60\n",
    "    \n",
    "CV MSE before feature selection: 3.98\n",
    "__init__: \n",
    "CV MSE after feature selection: 6.33\n",
    "    \n",
    "    \n",
    "CV MSE before feature selection: 3.98\n",
    "__init__: \n",
    "CV MSE after feature selection: 6.86\n",
    "In [17]:\n",
    "\n",
    "* size =50 , features//3\n",
    "CV MSE before feature selection: 3.98\n",
    "__init__: \n",
    "CV MSE after feature selection: 10.70\n",
    "\n",
    "\n",
    "*n_gen=4, size=1000, n_best=16, n_rand=4, n_children=100 , features//3\n",
    "CV MSE before feature selection: 3.98\n",
    "__init__: \n",
    "CV MSE after feature selection: 12.98\n",
    "\n",
    "*n_gen=4, size=1000, n_best=16, n_rand=4, n_children=100, mutation_rate=0.05 , n_features//2\n",
    "CV MSE before feature selection: 3.98\n",
    "__init__: \n",
    "CV MSE after feature selection: 8.35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV MSE after feature selection: 18.10\n",
    "CV MSE after feature selection: 14.82\n",
    "    \n",
    "CV MSE after feature selection: 14.39\n",
    "chromosome[mask] shape:  (30494,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = -1.0 * cross_val_score(clf_mnb, X[:,sel.support_], y, cv=10, scoring='accuracy')\n",
    "print(\"CV MSE before feature selection: {:.2f}\".format(np.mean(score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[:,chromosome]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = X.toarray()\n",
    "print (v[2938])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_top10(classifier, vectorizer, categories):\n",
    "    classifier.fit(X, y)\n",
    "    y_pred = classifier.predict(X)\n",
    "    print (\"Predicted Class Labels:\",y_pred.shape)\n",
    "    \n",
    "    print (\"vectorizer.get_feature_names(): \", len (vectorizer.get_feature_names()))\n",
    "    data_train_vectors = vectorizer.fit_transform(data_train.data)\n",
    "    print (\"data_train_vectors: \", data_train_vectors.shape)\n",
    "    feature_names = np.asarray(vectorizer.get_feature_names())\n",
    "    arr = []\n",
    "    for i, category in enumerate(categories):\n",
    "#         top10 = np.argsort(classifier.coef_[i])[-10:]\n",
    "        labels = enumerate(y_pred)\n",
    "        ll = []\n",
    "        count =0\n",
    "        for j, l in labels:\n",
    "#             print (\"j: \", j)\n",
    "#             print (\"l: \", l)\n",
    "            if l == i and count <10:\n",
    "                ll.append(j)\n",
    "                count = count + 1\n",
    "#         print (\"ll: \", ll)\n",
    "        if ll != []:\n",
    "            arr.append(ll)\n",
    "#             print (\"arr: \", arr)\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "# dataset = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "X, y = dataset.data, dataset.target\n",
    "vectorizer = HashingVectorizer(stop_words='english', non_negative=True)\n",
    "X_vectorized = vectorizer.transform(X)\n",
    "features = features = dataset.target_names\n",
    "dataset = load_boston()\n",
    "X, y = dataset.data, dataset.target\n",
    "features = dataset.feature_names\n",
    "\n",
    "est = MultinomialNB(alpha=.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB 10-Cross Validation accuracy: -0.9106842643537906\n",
      "score :  -0.9197605276045913\n",
      "score :  -0.9181684051039957\n",
      "score :  -0.9186974479679637\n",
      "score :  -0.9208393450780991\n",
      "score :  -0.9211013566277824\n",
      "score :  -0.921906362048\n",
      "score :  -0.9219045742695972\n",
      "score :  -0.9227059983829807\n",
      "score :  -0.921908865706228\n",
      "score :  -0.9219113770260359\n",
      "score :  -0.9232511370179765\n",
      "score :  -0.9235131533542255\n",
      "score :  -0.9248500546172744\n",
      "score :  -0.925384098095738\n",
      "score :  -0.9251174371714331\n",
      "score :  -0.9253826711264967\n",
      "score :  -0.9259238676454971\n",
      "score :  -0.9267267244743067\n",
      "score :  -0.9267267244743067\n",
      "score :  -0.9269966106828498\n",
      "score :  -0.9267292310037053\n",
      "score :  -0.9267292310037053\n",
      "score :  -0.9275320878325152\n",
      "score :  -0.9275320878325152\n",
      "score :  -0.9280679219643957\n",
      "score :  -0.9280679219643957\n",
      "score :  -0.9280679219643957\n",
      "score :  -0.9286005356024474\n",
      "score :  -0.9286012514822725\n",
      "score :  -0.9286023243404694\n",
      "score :  -0.9288700638729995\n",
      "score :  -0.9288697059350086\n",
      "score :  -0.9294048232312881\n",
      "score :  -0.9302066062422819\n",
      "score :  -0.929939582589577\n",
      "score :  -0.9299392256073619\n",
      "score :  -0.930206248304291\n",
      "score :  -0.9302066052865061\n",
      "score :  -0.9302080360826939\n",
      "score :  -0.9302069641802728\n",
      "score :  -0.9304743438594171\n",
      "score :  -0.9304743438594171\n",
      "score :  -0.9304743438594171\n",
      "score :  -0.931275770847815\n",
      "score :  -0.931275770847815\n",
      "score :  -0.9315431505269594\n",
      "score :  -0.9315431505269594\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_boston , fetch_20newsgroups , load_wine\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import HashingVectorizer ,TfidfVectorizer\n",
    "\n",
    "\n",
    "SEED = 2018\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "#==============================================================================\n",
    "# Data \n",
    "#==============================================================================\n",
    "\n",
    "# dataset = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'))\n",
    "cats =['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware']\n",
    "dataset = fetch_20newsgroups(subset='all', categories=cats,shuffle=True, random_state=42)\n",
    "\n",
    "X1, y = dataset.data, dataset.target\n",
    "# vectorizer = HashingVectorizer(stop_words='english', non_negative=True)\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.3, stop_words='english',smooth_idf =True)\n",
    "\n",
    "\n",
    "X = vectorizer.fit_transform(X1)\n",
    "features = features = dataset.target_names\n",
    "\n",
    "\n",
    "# dataset = load_wine()\n",
    "# X, y = dataset.data, dataset.target\n",
    "# features = dataset.feature_names\n",
    "\n",
    "#==============================================================================\n",
    "# CV MSE before feature selection\n",
    "#==============================================================================\n",
    "# est = LinearRegression()\n",
    "est = MultinomialNB(alpha=.01)\n",
    "# score = -1.0 * cross_val_score(est, X, y, cv=5, scoring=\"neg_mean_squared_error\")\n",
    "# score = -1.0 *cross_val_score(est, X, y, cv=5, scoring='accuracy').mean()\n",
    "# print(\"CV MSE before feature selection: {:.2f}\".format(np.mean(score)))\n",
    "\n",
    "# est.fit(X=train_data, y=train_labels)\n",
    "print (\"MultinomialNB 10-Cross Validation accuracy:\",-1.0 *cross_val_score(est, X, y, cv=5, scoring='accuracy').mean())\n",
    "#==============================================================================\n",
    "# Class performing feature selection with genetic algorithm\n",
    "#==============================================================================\n",
    "class GeneticSelector():\n",
    "    def __init__(self, estimator, n_gen, size, n_best, n_rand, \n",
    "                 n_children, mutation_rate):\n",
    "        # Estimator \n",
    "        self.estimator = estimator\n",
    "        # Number of generations\n",
    "        self.n_gen = n_gen\n",
    "        # Number of chromosomes in population\n",
    "        self.size = size\n",
    "        # Number of best chromosomes to select\n",
    "        self.n_best = n_best\n",
    "        # Number of random chromosomes to select\n",
    "        self.n_rand = n_rand\n",
    "        # Number of children created during crossover\n",
    "        self.n_children = n_children\n",
    "        # Probablity of chromosome mutation\n",
    "        self.mutation_rate = mutation_rate\n",
    "        \n",
    "        if int((self.n_best + self.n_rand) / 2) * self.n_children != self.size:\n",
    "            raise ValueError(\"The population size is not stable.\")  \n",
    "            \n",
    "    def initilize(self):\n",
    "        population = []\n",
    "        for i in range(self.size):\n",
    "            chromosome = np.ones(self.n_features, dtype=np.bool)\n",
    "            mask = np.random.rand(len(chromosome)) < 0.3\n",
    "            chromosome[mask] = False\n",
    "            population.append(chromosome)\n",
    "        return population\n",
    "\n",
    "    def fitness(self, population):\n",
    "        X, y = self.dataset\n",
    "        scores = []\n",
    "        for chromosome in population:\n",
    "#             score = -1.0 * np.mean(cross_val_score(self.estimator, X[:,chromosome], y, \n",
    "#                                                        cv=5, \n",
    "#                                                        scoring=\"neg_mean_squared_error\"))\n",
    "\n",
    "#             self.estimator.fit(X=train_data, y=train_labels)\n",
    "            score = -1.0 *cross_val_score(self.estimator, X[:,chromosome], y, cv=5, scoring='accuracy').mean()\n",
    "#             print (\"MultinomialNB 10-Cross Validation accuracy:\",cross_val_score(self.estimator, X[:,sel.support_], y, cv=5, scoring='accuracy').mean())\n",
    "            scores.append(score)\n",
    "        scores, population = np.array(scores), np.array(population) \n",
    "        inds = np.argsort(scores)\n",
    "        return list(scores[inds]), list(population[inds,:])\n",
    "\n",
    "    def select(self, population_sorted):\n",
    "        \n",
    "        population_next = []\n",
    "        for i in range(self.n_best):\n",
    "            population_next.append(population_sorted[i])\n",
    "        for i in range(self.n_rand):\n",
    "            population_next.append(random.choice(population_sorted))\n",
    "        random.shuffle(population_next)\n",
    "        return population_next\n",
    "\n",
    "    def crossover(self, population):\n",
    "        population_next = []\n",
    "        for i in range(int(len(population)/2)):\n",
    "            for j in range(self.n_children):\n",
    "                chromosome1, chromosome2 = population[i], population[len(population)-1-i]\n",
    "                child = chromosome1\n",
    "                mask = np.random.rand(len(child)) > 0.5\n",
    "                child[mask] = chromosome2[mask]\n",
    "                population_next.append(child)\n",
    "        return population_next\n",
    "\t\n",
    "    def mutate(self, population):\n",
    "        population_next = []\n",
    "        for i in range(len(population)):\n",
    "            chromosome = population[i]\n",
    "            if random.random() < self.mutation_rate:\n",
    "                mask = np.random.rand(len(chromosome)) < 0.05\n",
    "                chromosome[mask] = False\n",
    "            population_next.append(chromosome)\n",
    "        return population_next\n",
    "\n",
    "    def generate(self, population):\n",
    "        # Selection, crossover and mutation\n",
    "        scores_sorted, population_sorted = self.fitness(population)\n",
    "        population = self.select(population_sorted)\n",
    "        population = self.crossover(population)\n",
    "        population = self.mutate(population)\n",
    "        # History\n",
    "        self.chromosomes_best.append(population_sorted[0])\n",
    "        self.scores_best.append(scores_sorted[0])\n",
    "        print(\"score : \", scores_sorted[0])\n",
    "        self.scores_avg.append(np.mean(scores_sorted))\n",
    "        \n",
    "        return population\n",
    "\n",
    "    def fit(self, X, y):\n",
    " \n",
    "        self.chromosomes_best = []\n",
    "        self.scores_best, self.scores_avg  = [], []\n",
    "        \n",
    "        self.dataset = X, y\n",
    "        self.n_features = X.shape[1]\n",
    "        \n",
    "        population = self.initilize()\n",
    "        for i in range(self.n_gen):\n",
    "            population = self.generate(population)\n",
    "            \n",
    "        return self \n",
    "    \n",
    "    @property\n",
    "    def support_(self):\n",
    "        return self.chromosomes_best[-1]\n",
    "\n",
    "    def plot_scores(self):\n",
    "        plt.plot(self.scores_best, label='Best')\n",
    "        plt.plot(self.scores_avg, label='Average')\n",
    "        plt.legend()\n",
    "        plt.ylabel('Scores')\n",
    "        plt.xlabel('Generation')\n",
    "        plt.show()\n",
    "# (self.n_best + self.n_rand) / 2) * self.n_children != self.size\n",
    "sel = GeneticSelector(estimator=MultinomialNB(alpha=.3), \n",
    "                       n_gen=100, size=200, n_best=20, n_rand=80, n_children=4, mutation_rate=0.01)\n",
    "sel.fit(X, y)\n",
    "sel.plot_scores()\n",
    "# print(\"chromosomes_best: \",sel.chromosomes_best)\n",
    "# score = -1.0 * cross_val_score(est, X[:,sel.support_], y, cv=5, scoring=\"neg_mean_squared_error\")\n",
    "# print(\"CV MSE after feature selection: {:.2f}\".format(np.mean(score)))\n",
    "# accuracy = -1.0 *cross_val_score(est, X[:,sel.support_], y, scoring='accuracy', cv = 10).mean()\n",
    "# # print(accuracy)\n",
    "# print (\"MultinomialNB 10-Cross Validation accuracy:\",accuracy)\n",
    "score = -1.0 *cross_val_score(est, X[:,sel.support_], y, scoring='accuracy', cv = 5)\n",
    "print(\"CV MSE after feature selection: {:.2f}\".format(np.mean(score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chromosomes_best:  [ True  True False ...  True False  True]\n"
     ]
    }
   ],
   "source": [
    "print(\"chromosomes_best: \",sel.chromosomes_best[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1.3214408061336371\n",
    "---\n",
    "n_gen=100, size=200, n_best=20, n_rand=80, n_children=4, mutation_rate=0.01)\n",
    "-0.9368936152715097\n",
    "----\n",
    "\n",
    "CV MSE after feature selection: 13.67\n",
    "CV MSE after feature selection: 13.64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " n_gen=50, size=40, n_best=4, n_rand=16, n_children=4, mutation_rate=0.01)\n",
    "0.923780146410006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " n_gen=50, size=200, n_best=20, n_rand=60, n_children=5, mutation_rate=0.05)\n",
    "1.2292404091555822\n",
    "-----------------\n",
    "n_gen=50, size=200, n_best=20, n_rand=60, n_children=5, mutation_rate=0.01)\n",
    "1.219852777047302\n",
    "-----------------\n",
    "n_gen=50, size=200, n_best=20, n_rand=60, n_children=5, mutation_rate=0.01\n",
    "1.219852777047302\n",
    "1.15\n",
    "-----------------\n",
    " n_gen=50, size=200, n_best=10, n_rand=70, n_children=5, mutation_rate=0.01\n",
    "score :  1.2308285914517334\n",
    "    1.11\n",
    "-----------------\n",
    " n_gen=50, size=320, n_best=10, n_rand=70, n_children=8, mutation_rate=0.01)\n",
    "    1.2372503569489233\n",
    "    1.18\n",
    " -----------------   \n",
    "n_gen=50, size=320, n_best=20, n_rand=300, n_children=2, mutation_rate=0.01)\n",
    " 1.265602689350406\n",
    "1.15\n",
    "-----------------\n",
    " n_gen=50, size=200, n_best=20, n_rand=80, n_children=4, mutation_rate=0.01)\n",
    "1.2377726200104433\n",
    "1.15\n",
    "-----------------\n",
    "n_gen=50, size=100, n_best=5, n_rand=35, n_children=5, mutation_rate=0.01)\n",
    "1.2727858395525313\n",
    "1.23\n",
    "-----------------\n",
    "n_gen=50, size=100, n_best=10, n_rand=30, n_children=5, mutation_rate=0.01)\n",
    "1.3276356122636421\n",
    "1.22\n",
    "----------------\n",
    "n_gen=50, size=400, n_best=40, n_rand=160, n_children=4, mutation_rate=0.01\n",
    "1.2011529345999037\n",
    "1.08\n",
    "----------------\n",
    "n_gen=50, size=400, n_best=20, n_rand=180, n_children=4, mutation_rate=0.01)\n",
    "1.219838801132914\n",
    "1.12\n",
    "----------------\n",
    "n_gen=50, size=400, n_best=60, n_rand=140, n_children=4, mutation_rate=0.01)\n",
    "1.2128997904157237\n",
    "1.10\n",
    "--------------\n",
    " n_gen=50, size=400, n_best=60, n_rand=140, n_children=4, mutation_rate=0.01)\n",
    "    1.10\n",
    "    1.2128997904157237\n",
    "--------------\n",
    "n_gen=500, size=400, n_best=40, n_rand=160, n_children=4, mutation_rate=0.01)\n",
    "1.1939240208372737\n",
    "1.12\n",
    "--------------\n",
    "n_gen=50, size=400, n_best=40, n_rand=160, n_children=4, mutation_rate=0.01)\n",
    "-0.933947066856045"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_arr = geek.random.randint(low = 0, high = 3, size = 5) \n",
    "print (\"Output 1D Array filled with random integers : \", out_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
